{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCQ (Multiple Choice Question) 평가 튜토리얼\n",
    "\n",
    "## MCQDataset\n",
    "\n",
    "이 튜토리얼에서는 Huggingface의 객관식 dataset을 불러와서 평가 후 재업로드하는 과정까지 경험해볼 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터셋 불러오기\n",
    "먼저 HuggingFace Hub에서 데이터셋을 불러오는 방법을 알아보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmetrics.llmdataset import MCQDataset\n",
    "from langmetrics.llmtestcase import MCQTestCase\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('sickgpt/001_MedQA_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'expected_output', 'choices'],\n",
       "        num_rows: 10178\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'expected_output', 'choices'],\n",
       "        num_rows: 1273\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 MCQDataset을 이용해서 불러와봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 MCQTestCase는 input, choices, expected_output을 고정으로 받습니다. 그런데 위에 Dataset은 input이 question이라는 열로 되어있네요. field_mapping 인자를 이용해서 column을 매핑해주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': str,\n",
       " 'choices': typing.List[str],\n",
       " 'expected_output': typing.Union[int, str],\n",
       " 'output': typing.Optional[str],\n",
       " 'reasoning': typing.Optional[str]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCQTestCase.__annotations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 사용법\n",
    "field_mapping = {\n",
    "    'input': 'question',  # 데이터셋의 'question' 필드를 'input'으로 매핑\n",
    "    'expected_output': 'expected_output',\n",
    "    'choices': 'choices'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = MCQDataset.from_huggingface_hub('sickgpt/001_MedQA_raw', field_mapping=field_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MCQDataset.from_huggingface_hub('sickgpt/001_MedQA_raw', field_mapping=field_mapping, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1273"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 evaluate을 진행해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmetrics.llmfactory import LLMFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt-4o',\n",
       " 'gpt-4o-mini',\n",
       " 'deepseek-v3',\n",
       " 'deepseek-reasoner',\n",
       " 'claude-3.5-sonnet',\n",
       " 'claude-3.5-haiku',\n",
       " 'naver']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLMFactory.get_model_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmetrics.llmfactory import LLMFactory\n",
    "# LLM 모델 생성\n",
    "gpt_4o_mini = LLMFactory.create_llm('gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deepseek_r1 = LLMFactory.create_llm('deepseek-reasoner', temperature=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmetrics.metrics import MCQMetric\n",
    "metric = MCQMetric(\n",
    "    answer_model=gpt_4o_mini,\n",
    "    template_language='en',  # 'ko' 또는 'en'\n",
    "    generate_template_type='reasoning'  # 'reasoning' 또는 'only_answer'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langmetrics.metrics import MCQMetric\n",
    "# r1_metric = MCQMetric(\n",
    "#     answer_model=deepseek_r1,\n",
    "#     template_language='en',  # 'ko' 또는 'en'\n",
    "#     generate_template_type='reasoning', # 'reasoning' 또는 'only_answer'\n",
    "#     verbose_mode=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "async를 통해서 빠르게 추론을 할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCQTestCase(input='A junior orthopaedic surgery resident is completing a carpal tunnel repair with the department chairman as the attending physician. During the case, the resident inadvertently cuts a flexor tendon. The tendon is repaired without complication. The attending tells the resident that the patient will do fine, and there is no need to report this minor complication that will not harm the patient, as he does not want to make the patient worry unnecessarily. He tells the resident to leave this complication out of the operative report. Which of the following is the correct next action for the resident to take?', choices=['Disclose the error to the patient and put it in the operative report', 'Tell the attending that he cannot fail to disclose this mistake', 'Report the physician to the ethics committee', 'Refuse to dictate the operative report'], expected_output='B', output=None, reasoning=None)\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await metric.ameasure(test_dataset[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r1_results = await r1_metric.ameasure(test_dataset[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "약 1200개의 달하는 test를 단 30초만에 모두 추론한 것을 확인할 수 있습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = sum([i.score for i in results]) / len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r1_scores = sum([i.score for i in r1_results]) / len(r1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "📝 문제: A junior orthopaedic surgery resident is completing a carpal tunnel repair with the department chairman as the attending physician. During the case, the resident inadvertently cuts a flexor tendon. The tendon is repaired without complication. The attending tells the resident that the patient will do fine, and there is no need to report this minor complication that will not harm the patient, as he does not want to make the patient worry unnecessarily. He tells the resident to leave this complication out of the operative report. Which of the following is the correct next action for the resident to take?\n",
      "\n",
      "🤔 제출한 답: {\n",
      "    \"reasoning\": \"In this scenario, the resident faces an ethical dilemma involving disclosure of a medical error. It is essential to maintain transparency in medical practice for patient safety and trust. While the attending physician suggests not reporting the error, the resident has a duty to prioritize the patient's right to know about any complications that occurred during their surgery, regardless of the perceived severity. Therefore, the best course of action would be to disclose the error to the patient and include it in the operative report, as this aligns with ethical standards in medicine. So the answer is A.\",\n",
      "    \"answer\": \"A\"\n",
      "}\n",
      "📋 선택지: ['Disclose the error to the patient and put it in the operative report', 'Tell the attending that he cannot fail to disclose this mistake', 'Report the physician to the ethics committee', 'Refuse to dictate the operative report']\n",
      "💡 정답: B\n",
      "\n",
      "📊 채점 결과: ❌ 오답\n",
      "\n",
      "💭 추론 과정:\n",
      "In this scenario, the resident faces an ethical dilemma involving disclosure of a medical error. It is essential to maintain transparency in medical practice for patient safety and trust. While the attending physician suggests not reporting the error, the resident has a duty to prioritize the patient's right to know about any complications that occurred during their surgery, regardless of the perceived severity. Therefore, the best course of action would be to disclose the error to the patient and include it in the operative report, as this aligns with ethical standards in medicine. So the answer is A.\n",
      "\n",
      "ℹ️ 메타데이터: {'language': 'en', 'student_token_usage': {'completion_tokens': 124, 'prompt_tokens': 279, 'total_tokens': 403}}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"question\": [result.question for result in results],\n",
    "    \"choice\": [\", \".join(result.choice) for result in results],  # 리스트를 문자열로 변환\n",
    "    \"predicted\": [result.predicted for result in results],\n",
    "    \"score\": [result.score for result in results],\n",
    "    \"ground_truth\": [result.ground_truth for result in results],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(data)\n",
    "# df.to_csv('deepseek_medqa_result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
