{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCQ (Multiple Choice Question) í‰ê°€ íŠœí† ë¦¬ì–¼\n",
    "\n",
    "ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” LLMì„ ì‚¬ìš©í•˜ì—¬ ê°ê´€ì‹ ë¬¸ì œë¥¼ í‰ê°€í•˜ëŠ” ë°©ë²•ì„ ë°°ì›Œë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "## ì£¼ìš” ê¸°ëŠ¥\n",
    "- ê°ê´€ì‹ ë¬¸ì œì˜ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„±\n",
    "- LLMì„ ì‚¬ìš©í•œ ë¬¸ì œ í•´ê²°\n",
    "- ë‹¤êµ­ì–´ ì§€ì› (í•œêµ­ì–´/ì˜ì–´)\n",
    "- ë¹„ë™ê¸° ì‹¤í–‰ ì§€ì›"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmetrics.llmfactory import LLMFactory\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MCQ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì •ì˜\n",
    "\n",
    "## LLMTestCase í´ë˜ìŠ¤ ì •ì˜\n",
    "LLMTestCase í´ë˜ìŠ¤ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í•„ë“œë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•„ë“œì˜ ì˜ë¯¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "- input: LLMì— ì…ë ¥í•  ì§ˆë¬¸\n",
    "- choices: ì„ íƒ ê°€ëŠ¥í•œ ë‹µë³€ë“¤ì˜ ë¦¬ìŠ¤íŠ¸\n",
    "- expected_output: ì •ë‹µ (ì¸ë±ìŠ¤ ë˜ëŠ” ë¬¸ìì—´)\n",
    "- output: LLMì´ ì‹¤ì œë¡œ ì¶œë ¥í•œ ë‹µë³€ (ì„ íƒì‚¬í•­)\n",
    "- reasoning: LLMì˜ ë‹µë³€ ë„ì¶œ ê³¼ì • (ì„ íƒì‚¬í•­)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„± ì˜ˆì‹œ\n",
    "ê°„ë‹¨í•œ í€´ì¦ˆ ë¬¸ì œë¥¼ ë§Œë“¤ì–´ MCQTestCaseë¥¼ ì‚¬ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¼ë°˜ìƒì‹ ë¬¸ì œ:\n",
      "ì§ˆë¬¸: í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?\n",
      "ì„ íƒì§€: ['ëŸ°ë˜', 'íŒŒë¦¬', 'ë² ë¥¼ë¦°', 'ë§ˆë“œë¦¬ë“œ']\n",
      "ì •ë‹µ ì¸ë±ìŠ¤: B\n",
      "\n",
      "ì˜ë£Œ ë¬¸ì œ:\n",
      "ì§ˆë¬¸: ì„ì‹  22ì£¼ì°¨ì¸ 23ì„¸ ì„ì‚°ë¶€ê°€ ë°°ë‡¨ ì‹œ í†µì¦ì„ í˜¸ì†Œí•©ë‹ˆë‹¤. 1ì¼ ì „ë¶€í„° ì‹œì‘ë˜ì—ˆìœ¼ë©° ìˆ˜ë¶„ ì„­ì·¨ ì¦ê°€ì™€ í¬ëœë² ë¦¬ ì¶”ì¶œë¬¼ ë³µìš©ì—ë„ ë¶ˆêµ¬í•˜ê³  ì•…í™”ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì²´ì˜¨ 36.5Â°C, í˜ˆì•• 122/77mmHg, ë§¥ë°• 80íšŒ/ë¶„, í˜¸í¡ìˆ˜ 19íšŒ/ë¶„, ì‚°ì†Œí¬í™”ë„ 98%ì…ë‹ˆë‹¤. ì‹ ì²´ê²€ì‚¬ìƒ ì²™ì¶”ê° ì••í†µì€ ì—†ìœ¼ë©° ì„ì‹ í•œ ìê¶ì´ ê´€ì°°ë©ë‹ˆë‹¤. ê°€ì¥ ì ì ˆí•œ ì¹˜ë£ŒëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ?\n",
      "ì„ íƒì§€: ['Ampicillin', 'Ceftriaxone', 'Ciprofloxacin', 'Nitrofurantoin']\n",
      "ì •ë‹µ: A\n",
      "ì¶”ë¡ : A\n"
     ]
    }
   ],
   "source": [
    "from langmetrics.llmtestcase import LLMTestCase\n",
    "# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì˜ˆì‹œ ìƒì„±\n",
    "simple_testcase = LLMTestCase(\n",
    "    input=\"í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?\",\n",
    "    choices=[\"ëŸ°ë˜\", \"íŒŒë¦¬\", \"ë² ë¥¼ë¦°\", \"ë§ˆë“œë¦¬ë“œ\"],\n",
    "    expected_output=\"B\"\n",
    ")\n",
    "\n",
    "medical_testcase = LLMTestCase(\n",
    "    input=\"ì„ì‹  22ì£¼ì°¨ì¸ 23ì„¸ ì„ì‚°ë¶€ê°€ ë°°ë‡¨ ì‹œ í†µì¦ì„ í˜¸ì†Œí•©ë‹ˆë‹¤. 1ì¼ ì „ë¶€í„° ì‹œì‘ë˜ì—ˆìœ¼ë©° ìˆ˜ë¶„ ì„­ì·¨ ì¦ê°€ì™€ í¬ëœë² ë¦¬ ì¶”ì¶œë¬¼ ë³µìš©ì—ë„ ë¶ˆêµ¬í•˜ê³  ì•…í™”ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì²´ì˜¨ 36.5Â°C, í˜ˆì•• 122/77mmHg, ë§¥ë°• 80íšŒ/ë¶„, í˜¸í¡ìˆ˜ 19íšŒ/ë¶„, ì‚°ì†Œí¬í™”ë„ 98%ì…ë‹ˆë‹¤. ì‹ ì²´ê²€ì‚¬ìƒ ì²™ì¶”ê° ì••í†µì€ ì—†ìœ¼ë©° ì„ì‹ í•œ ìê¶ì´ ê´€ì°°ë©ë‹ˆë‹¤. ê°€ì¥ ì ì ˆí•œ ì¹˜ë£ŒëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ?\",\n",
    "    choices=[\"Ampicillin\", \"Ceftriaxone\", \"Ciprofloxacin\", \"Nitrofurantoin\"],\n",
    "    expected_output=\"A\",\n",
    "    output=\"A\"\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¶œë ¥\n",
    "print(\"ì¼ë°˜ìƒì‹ ë¬¸ì œ:\")\n",
    "print(f\"ì§ˆë¬¸: {simple_testcase.input}\")\n",
    "print(f\"ì„ íƒì§€: {simple_testcase.choices}\")\n",
    "print(f\"ì •ë‹µ ì¸ë±ìŠ¤: {simple_testcase.expected_output}\")\n",
    "print(\"\\nì˜ë£Œ ë¬¸ì œ:\")\n",
    "print(f\"ì§ˆë¬¸: {medical_testcase.input}\")\n",
    "print(f\"ì„ íƒì§€: {medical_testcase.choices}\")\n",
    "print(f\"ì •ë‹µ: {medical_testcase.expected_output}\")\n",
    "print(f\"ì¶”ë¡ : {medical_testcase.output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LLMì„ ì´ìš©í•˜ì—¬ MCQ í‰ê°€\n",
    "\n",
    "LLMì„ ì„¤ì •í•˜ê³  MCQ í‰ê°€ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM ëª¨ë¸ ìƒì„±\n",
    "openai_llm = LLMFactory.create_llm('gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í‰ê°€ë¥¼ ìœ„í•˜ì—¬ MCQMetric classë¥¼ í˜¸ì¶œí•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. MCQMetricì€ LLM(Large Language Model)ì˜ ê°ê´€ì‹ ë¬¸ì œ ë‹µë³€ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë©”íŠ¸ë¦­ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.\n",
    "\n",
    "MCQMetricì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ë¨¼ì € ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. ê¸°ë³¸ì ì¸ ì„¤ì • ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì£¼ìš” ë§¤ê°œë³€ìˆ˜ :\n",
    "\n",
    "`template_language`: í…œí”Œë¦¿ ì–¸ì–´ ì„ íƒ ('ko' ë˜ëŠ” 'en')\n",
    "\n",
    "`generate_template_type`: ë‹µë³€ ìƒì„± ë°©ì‹ ('reasoning': í’€ì´ ê³¼ì • í¬í•¨, 'only_answer': ë‹µë§Œ ìƒì„±)\n",
    "\n",
    "`verbose_mode`: ìƒì„¸ ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmetrics.metrics import MCQMetric\n",
    "metric = MCQMetric(\n",
    "    answer_model=openai_llm,\n",
    "    template_language='en',  # 'ko' ë˜ëŠ” 'en'\n",
    "    generate_template_type='reasoning',  # 'reasoning' ë˜ëŠ” 'only_answer'\n",
    "    verbose_mode=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?\n",
      "Generated answer: {\n",
      "    \"reasoning\": \"í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì—­ì‚¬ì ìœ¼ë¡œ ì•Œë ¤ì§„ ë°”ì™€ ê°™ì´ íŒŒë¦¬ì…ë‹ˆë‹¤. ëŸ°ë˜ì€ ì˜êµ­ì˜ ìˆ˜ë„, ë² ë¥¼ë¦°ì€ ë…ì¼ì˜ ìˆ˜ë„, ë§ˆë“œë¦¬ë“œëŠ” ìŠ¤í˜ì¸ì˜ ìˆ˜ë„ì…ë‹ˆë‹¤. ë”°ë¼ì„œ í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ì— ëŒ€í•œ ì •ë‹µì€ íŒŒë¦¬ì…ë‹ˆë‹¤. So the answer is B.\",\n",
      "    \"answer\": \"B\"\n",
      "}\n",
      "Expected answer: B\n",
      "Is correct: False\n",
      "Reasoning: í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì—­ì‚¬ì ìœ¼ë¡œ ì•Œë ¤ì§„ ë°”ì™€ ê°™ì´ íŒŒë¦¬ì…ë‹ˆë‹¤. ëŸ°ë˜ì€ ì˜êµ­ì˜ ìˆ˜ë„, ë² ë¥¼ë¦°ì€ ë…ì¼ì˜ ìˆ˜ë„, ë§ˆë“œë¦¬ë“œëŠ” ìŠ¤í˜ì¸ì˜ ìˆ˜ë„ì…ë‹ˆë‹¤. ë”°ë¼ì„œ í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ì— ëŒ€í•œ ì •ë‹µì€ íŒŒë¦¬ì…ë‹ˆë‹¤. So the answer is B.\n"
     ]
    }
   ],
   "source": [
    "result = metric.measure(simple_testcase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inputì— ë“¤ì–´ê°€ simple_testcaseëŠ” ì •ë‹µê°’ê³¼ í•¨ê»˜ ì¶œë ¥ì´ ë¨ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMTestCase(input='í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?', output='{\\n    \"reasoning\": \"í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì—­ì‚¬ì ìœ¼ë¡œ ì•Œë ¤ì§„ ë°”ì™€ ê°™ì´ íŒŒë¦¬ì…ë‹ˆë‹¤. ëŸ°ë˜ì€ ì˜êµ­ì˜ ìˆ˜ë„, ë² ë¥¼ë¦°ì€ ë…ì¼ì˜ ìˆ˜ë„, ë§ˆë“œë¦¬ë“œëŠ” ìŠ¤í˜ì¸ì˜ ìˆ˜ë„ì…ë‹ˆë‹¤. ë”°ë¼ì„œ í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ì— ëŒ€í•œ ì •ë‹µì€ íŒŒë¦¬ì…ë‹ˆë‹¤. So the answer is B.\",\\n    \"answer\": \"B\"\\n}', expected_output='B', context=None, retrieval_context=None, reasoning='í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì—­ì‚¬ì ìœ¼ë¡œ ì•Œë ¤ì§„ ë°”ì™€ ê°™ì´ íŒŒë¦¬ì…ë‹ˆë‹¤. ëŸ°ë˜ì€ ì˜êµ­ì˜ ìˆ˜ë„, ë² ë¥¼ë¦°ì€ ë…ì¼ì˜ ìˆ˜ë„, ë§ˆë“œë¦¬ë“œëŠ” ìŠ¤í˜ì¸ì˜ ìˆ˜ë„ì…ë‹ˆë‹¤. ë”°ë¼ì„œ í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ì— ëŒ€í•œ ì •ë‹µì€ íŒŒë¦¬ì…ë‹ˆë‹¤. So the answer is B.', choices=['ëŸ°ë˜', 'íŒŒë¦¬', 'ë² ë¥¼ë¦°', 'ë§ˆë“œë¦¬ë“œ'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_testcase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ë¬¸ì œ: í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?\n",
      "\n",
      "ğŸ¤” LLM ë‹µ: {\n",
      "    \"reasoning\": \"í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì—­ì‚¬ì ìœ¼ë¡œ ì•Œë ¤ì§„ ë°”ì™€ ê°™ì´ íŒŒë¦¬ì…ë‹ˆë‹¤. ëŸ°ë˜ì€ ì˜êµ­ì˜ ìˆ˜ë„, ë² ë¥¼ë¦°ì€ ë…ì¼ì˜ ìˆ˜ë„, ë§ˆë“œë¦¬ë“œëŠ” ìŠ¤í˜ì¸ì˜ ìˆ˜ë„ì…ë‹ˆë‹¤. ë”°ë¼ì„œ í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ì— ëŒ€í•œ ì •ë‹µì€ íŒŒë¦¬ì…ë‹ˆë‹¤. So the answer is B.\",\n",
      "    \"answer\": \"B\"\n",
      "}\n",
      "ğŸ“‹ ì„ íƒì§€: ['ëŸ°ë˜', 'íŒŒë¦¬', 'ë² ë¥¼ë¦°', 'ë§ˆë“œë¦¬ë“œ']\n",
      "ğŸ’¡ ì •ë‹µ: B\n",
      "\n",
      "ğŸ“Š ì±„ì  ê²°ê³¼: âœ… ì •ë‹µ\n",
      "\n",
      "ğŸ’­ ì¶”ë¡  ê³¼ì •:\n",
      "í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì—­ì‚¬ì ìœ¼ë¡œ ì•Œë ¤ì§„ ë°”ì™€ ê°™ì´ íŒŒë¦¬ì…ë‹ˆë‹¤. ëŸ°ë˜ì€ ì˜êµ­ì˜ ìˆ˜ë„, ë² ë¥¼ë¦°ì€ ë…ì¼ì˜ ìˆ˜ë„, ë§ˆë“œë¦¬ë“œëŠ” ìŠ¤í˜ì¸ì˜ ìˆ˜ë„ì…ë‹ˆë‹¤. ë”°ë¼ì„œ í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ì— ëŒ€í•œ ì •ë‹µì€ íŒŒë¦¬ì…ë‹ˆë‹¤. So the answer is B.\n",
      "\n",
      "â„¹ï¸ ë©”íƒ€ë°ì´í„°: {'student_template_language': 'en', 'student_model_name': 'gpt-4o-mini-2024-07-18', 'student_token_usage': {'completion_tokens': 82, 'prompt_tokens': 149, 'total_tokens': 231}}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCQResultëŠ” to_dict()ì™€ from_dict() methodë¥¼ ì§€ì›í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = result.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?', 'choice': ['ëŸ°ë˜', 'íŒŒë¦¬', 'ë² ë¥¼ë¦°', 'ë§ˆë“œë¦¬ë“œ'], 'ground_truth': 'B', 'student_answer': '{\\n    \"reasoning\": \"í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì—­ì‚¬ì ìœ¼ë¡œ ì•Œë ¤ì§„ ë°”ì™€ ê°™ì´ íŒŒë¦¬ì…ë‹ˆë‹¤. ëŸ°ë˜ì€ ì˜êµ­ì˜ ìˆ˜ë„, ë² ë¥¼ë¦°ì€ ë…ì¼ì˜ ìˆ˜ë„, ë§ˆë“œë¦¬ë“œëŠ” ìŠ¤í˜ì¸ì˜ ìˆ˜ë„ì…ë‹ˆë‹¤. ë”°ë¼ì„œ í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ì— ëŒ€í•œ ì •ë‹µì€ íŒŒë¦¬ì…ë‹ˆë‹¤. So the answer is B.\",\\n    \"answer\": \"B\"\\n}', 'score': 1, 'reasoning': 'í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì—­ì‚¬ì ìœ¼ë¡œ ì•Œë ¤ì§„ ë°”ì™€ ê°™ì´ íŒŒë¦¬ì…ë‹ˆë‹¤. ëŸ°ë˜ì€ ì˜êµ­ì˜ ìˆ˜ë„, ë² ë¥¼ë¦°ì€ ë…ì¼ì˜ ìˆ˜ë„, ë§ˆë“œë¦¬ë“œëŠ” ìŠ¤í˜ì¸ì˜ ìˆ˜ë„ì…ë‹ˆë‹¤. ë”°ë¼ì„œ í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ì— ëŒ€í•œ ì •ë‹µì€ íŒŒë¦¬ì…ë‹ˆë‹¤. So the answer is B.', 'metadata': {'student_template_language': 'en', 'student_model_name': 'gpt-4o-mini-2024-07-18', 'student_token_usage': {'completion_tokens': 82, 'prompt_tokens': 149, 'total_tokens': 231}}}\n"
     ]
    }
   ],
   "source": [
    "print(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MCQResult(question='í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?', student_answer='{\\n    \"reasoning\": \"í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì—­ì‚¬ì ìœ¼ë¡œ ì•Œë ¤ì§„ ë°”ì™€ ê°™ì´ íŒŒë¦¬ì…ë‹ˆë‹¤. ëŸ°ë˜ì€ ì˜êµ­ì˜ ìˆ˜ë„, ë² ë¥¼ë¦°ì€ ë…ì¼ì˜ ìˆ˜ë„, ë§ˆë“œë¦¬ë“œëŠ” ìŠ¤í˜ì¸ì˜ ìˆ˜ë„ì…ë‹ˆë‹¤. ë”°ë¼ì„œ í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ì— ëŒ€í•œ ì •ë‹µì€ íŒŒë¦¬ì…ë‹ˆë‹¤. So the answer is B.\",\\n    \"answer\": \"B\"\\n}', score=1, metadata={'student_template_language': 'en', 'student_model_name': 'gpt-4o-mini-2024-07-18', 'student_token_usage': {'completion_tokens': 82, 'prompt_tokens': 149, 'total_tokens': 231}}, reasoning='í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì—­ì‚¬ì ìœ¼ë¡œ ì•Œë ¤ì§„ ë°”ì™€ ê°™ì´ íŒŒë¦¬ì…ë‹ˆë‹¤. ëŸ°ë˜ì€ ì˜êµ­ì˜ ìˆ˜ë„, ë² ë¥¼ë¦°ì€ ë…ì¼ì˜ ìˆ˜ë„, ë§ˆë“œë¦¬ë“œëŠ” ìŠ¤í˜ì¸ì˜ ìˆ˜ë„ì…ë‹ˆë‹¤. ë”°ë¼ì„œ í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ì— ëŒ€í•œ ì •ë‹µì€ íŒŒë¦¬ì…ë‹ˆë‹¤. So the answer is B.', ground_truth='B', choice=['ëŸ°ë˜', 'íŒŒë¦¬', 'ë² ë¥¼ë¦°', 'ë§ˆë“œë¦¬ë“œ'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.from_dict(result_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MCQ í…œí”Œë¦¿ ì„¤ì •\n",
    "\n",
    "\n",
    "langmetricsì˜ Metricì€ custom templateì„ ì´ìš©í•  ìˆ˜ ìˆê³ , ì´ templateì€ langchainì˜ Templateì„ ì´ìš©í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, AIMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langmetrics.metrics import MCQTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë©”ì‹œì§€ë¥¼ ì„¤ì •í•˜ë˜, ë°˜ë“œì‹œ JSONì„ outputì„ ì¶œë ¥ìœ¼ë¡œ ë±‰ëŠ” templateì„ ì„¤ì •í•´ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt = ChatPromptTemplate.from_messages([\n",
    "    AIMessagePromptTemplate.from_template('ë‹¹ì‹ ì€ ì˜ë£Œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.'),\n",
    "    HumanMessagePromptTemplate.from_template(\"\"\"ë‹¤ìŒì˜ ê°ê´€ì‹ ë¬¸ì œë¥¼ í’€ì–´ì£¼ì„¸ìš”.\n",
    "ì¶”ë¡  ê³¼ì •ì„ ì„¤ëª…í•˜ê³  ì •ë‹µì€ ì•ŒíŒŒë²³(A, B, C, D ë“±)ìœ¼ë¡œë§Œ ë‹µí•´ì£¼ì„¸ìš”.\n",
    "\n",
    "**\n",
    "ì¤‘ìš” : ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”. 'answer' í‚¤ì—ëŠ” ì •ë‹µì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
    "JSON ì˜ˆì‹œ:\n",
    "{{\n",
    "\"answer\": \"<ì •ë‹µ>\"\n",
    "}}\n",
    "**\n",
    "\n",
    "ë¬¸ì œ:\n",
    "{question}\n",
    "\n",
    "ë³´ê¸°:\n",
    "{choices}\n",
    "\n",
    "JSON:\"\"\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCQTemplate í´ë˜ìŠ¤ëŠ” ì •ì˜ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°ê´€ì‹ ë¬¸ì œ í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_template = MCQTemplate(prompt_for_answer=evaluation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = MCQMetric(\n",
    "    openai_llm, \n",
    "    verbose_mode=True, \n",
    "    template_language='en',\n",
    "    template=answer_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?\n",
      "Generated answer: {\n",
      "    \"reasoning\": \"í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì—­ì‚¬ì ìœ¼ë¡œ ì•Œë ¤ì§„ ë°”ì™€ ê°™ì´ íŒŒë¦¬ì…ë‹ˆë‹¤. ëŸ°ë˜ì€ ì˜êµ­ì˜ ìˆ˜ë„, ë² ë¥¼ë¦°ì€ ë…ì¼ì˜ ìˆ˜ë„, ë§ˆë“œë¦¬ë“œëŠ” ìŠ¤í˜ì¸ì˜ ìˆ˜ë„ì…ë‹ˆë‹¤. ë”°ë¼ì„œ í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ì— ëŒ€í•œ ì •ë‹µì€ íŒŒë¦¬ì…ë‹ˆë‹¤. So the answer is B.\",\n",
      "    \"answer\": \"B\"\n",
      "}\n",
      "Expected answer: B\n",
      "Is correct: False\n",
      "Reasoning: í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì—­ì‚¬ì ìœ¼ë¡œ ì•Œë ¤ì§„ ë°”ì™€ ê°™ì´ íŒŒë¦¬ì…ë‹ˆë‹¤. ëŸ°ë˜ì€ ì˜êµ­ì˜ ìˆ˜ë„, ë² ë¥¼ë¦°ì€ ë…ì¼ì˜ ìˆ˜ë„, ë§ˆë“œë¦¬ë“œëŠ” ìŠ¤í˜ì¸ì˜ ìˆ˜ë„ì…ë‹ˆë‹¤. ë”°ë¼ì„œ í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ì— ëŒ€í•œ ì •ë‹µì€ íŒŒë¦¬ì…ë‹ˆë‹¤. So the answer is B.\n",
      "ğŸ“ ë¬¸ì œ: í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì…ë‹ˆê¹Œ?\n",
      "\n",
      "ğŸ¤” LLM ë‹µ: {\n",
      "    \"reasoning\": \"í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì—­ì‚¬ì ìœ¼ë¡œ ì•Œë ¤ì§„ ë°”ì™€ ê°™ì´ íŒŒë¦¬ì…ë‹ˆë‹¤. ëŸ°ë˜ì€ ì˜êµ­ì˜ ìˆ˜ë„, ë² ë¥¼ë¦°ì€ ë…ì¼ì˜ ìˆ˜ë„, ë§ˆë“œë¦¬ë“œëŠ” ìŠ¤í˜ì¸ì˜ ìˆ˜ë„ì…ë‹ˆë‹¤. ë”°ë¼ì„œ í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ì— ëŒ€í•œ ì •ë‹µì€ íŒŒë¦¬ì…ë‹ˆë‹¤. So the answer is B.\",\n",
      "    \"answer\": \"B\"\n",
      "}\n",
      "ğŸ“‹ ì„ íƒì§€: ['ëŸ°ë˜', 'íŒŒë¦¬', 'ë² ë¥¼ë¦°', 'ë§ˆë“œë¦¬ë“œ']\n",
      "ğŸ’¡ ì •ë‹µ: B\n",
      "\n",
      "ğŸ“Š ì±„ì  ê²°ê³¼: âœ… ì •ë‹µ\n",
      "\n",
      "ğŸ’­ ì¶”ë¡  ê³¼ì •:\n",
      "í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ëŠ” ì—­ì‚¬ì ìœ¼ë¡œ ì•Œë ¤ì§„ ë°”ì™€ ê°™ì´ íŒŒë¦¬ì…ë‹ˆë‹¤. ëŸ°ë˜ì€ ì˜êµ­ì˜ ìˆ˜ë„, ë² ë¥¼ë¦°ì€ ë…ì¼ì˜ ìˆ˜ë„, ë§ˆë“œë¦¬ë“œëŠ” ìŠ¤í˜ì¸ì˜ ìˆ˜ë„ì…ë‹ˆë‹¤. ë”°ë¼ì„œ í”„ë‘ìŠ¤ì˜ ìˆ˜ë„ì— ëŒ€í•œ ì •ë‹µì€ íŒŒë¦¬ì…ë‹ˆë‹¤. So the answer is B.\n",
      "\n",
      "â„¹ï¸ ë©”íƒ€ë°ì´í„°: {'student_template_language': 'en', 'student_model_name': '', 'student_token_usage': {'completion_tokens': None, 'prompt_tokens': None, 'total_tokens': None}}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(metric.measure(simple_testcase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
