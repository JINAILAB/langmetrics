{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCQ (Multiple Choice Question) 평가 튜토리얼\n",
    "\n",
    "이 튜토리얼에서는 LLM을 사용하여 객관식 문제를 평가하는 방법을 배워보겠습니다.\n",
    "\n",
    "## 주요 기능\n",
    "- 객관식 문제의 테스트 케이스 생성\n",
    "- LLM을 사용한 문제 해결\n",
    "- 다국어 지원 (한국어/영어)\n",
    "- 비동기 실행 지원"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 필요한 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmetrics.llmfactory import LLMFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MCQ 테스트 케이스 정의\n",
    "\n",
    "## MCQTestCase 클래스 정의\n",
    "MCQTestCase 클래스는 다음과 같은 필드로 구성되어 있습니다. 필드의 의미는 다음과 같습니다:\n",
    "- input: LLM에 입력할 질문\n",
    "- choices: 선택 가능한 답변들의 리스트\n",
    "- expected_output: 정답 (인덱스 또는 문자열)\n",
    "- output: LLM이 실제로 출력한 답변 (선택사항)\n",
    "- reasoning: LLM의 답변 도출 과정 (선택사항)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 테스트 케이스 생성 예시\n",
    "간단한 퀴즈 문제를 만들어 MCQTestCase를 사용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "일반상식 문제:\n",
      "질문: 프랑스의 수도는 어디입니까?\n",
      "선택지: ['런던', '파리', '베를린', '마드리드']\n",
      "정답 인덱스: B\n",
      "\n",
      "의료 문제:\n",
      "질문: 임신 22주차인 23세 임산부가 배뇨 시 통증을 호소합니다. 1일 전부터 시작되었으며 수분 섭취 증가와 크랜베리 추출물 복용에도 불구하고 악화되고 있습니다. 체온 36.5°C, 혈압 122/77mmHg, 맥박 80회/분, 호흡수 19회/분, 산소포화도 98%입니다. 신체검사상 척추각 압통은 없으며 임신한 자궁이 관찰됩니다. 가장 적절한 치료는 무엇입니까?\n",
      "선택지: ['Ampicillin', 'Ceftriaxone', 'Ciprofloxacin', 'Nitrofurantoin']\n",
      "정답: A\n",
      "추론: A\n"
     ]
    }
   ],
   "source": [
    "from langmetrics.llmtestcase import MCQTestCase\n",
    "# 테스트 케이스 예시 생성\n",
    "simple_testcase = MCQTestCase(\n",
    "    input=\"프랑스의 수도는 어디입니까?\",\n",
    "    choices=[\"런던\", \"파리\", \"베를린\", \"마드리드\"],\n",
    "    expected_output=\"B\"\n",
    ")\n",
    "\n",
    "medical_testcase = MCQTestCase(\n",
    "    input=\"임신 22주차인 23세 임산부가 배뇨 시 통증을 호소합니다. 1일 전부터 시작되었으며 수분 섭취 증가와 크랜베리 추출물 복용에도 불구하고 악화되고 있습니다. 체온 36.5°C, 혈압 122/77mmHg, 맥박 80회/분, 호흡수 19회/분, 산소포화도 98%입니다. 신체검사상 척추각 압통은 없으며 임신한 자궁이 관찰됩니다. 가장 적절한 치료는 무엇입니까?\",\n",
    "    choices=[\"Ampicillin\", \"Ceftriaxone\", \"Ciprofloxacin\", \"Nitrofurantoin\"],\n",
    "    expected_output=\"A\",\n",
    "    output=\"A\"\n",
    ")\n",
    "\n",
    "# 테스트 케이스 출력\n",
    "print(\"일반상식 문제:\")\n",
    "print(f\"질문: {simple_testcase.input}\")\n",
    "print(f\"선택지: {simple_testcase.choices}\")\n",
    "print(f\"정답 인덱스: {simple_testcase.expected_output}\")\n",
    "print(\"\\n의료 문제:\")\n",
    "print(f\"질문: {medical_testcase.input}\")\n",
    "print(f\"선택지: {medical_testcase.choices}\")\n",
    "print(f\"정답: {medical_testcase.expected_output}\")\n",
    "print(f\"추론: {medical_testcase.output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LLM을 이용하여 MCQ 평가\n",
    "\n",
    "LLM을 설정하고 MCQ 평가를 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 모델 생성\n",
    "deepseek_llm = LLMFactory.create_llm('deepseek-v3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가를 위하여 MCQMetric class를 호출하도록 하겠습니다. MCQMetric은 LLM(Large Language Model)의 객관식 문제 답변을 평가하기 위한 메트릭 클래스입니다.\n",
    "\n",
    "MCQMetric을 사용하기 위해서는 먼저 인스턴스를 생성해야 합니다. 기본적인 설정 방법은 다음과 같습니다:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주요 매개변수 :\n",
    "\n",
    "`template_language`: 템플릿 언어 선택 ('ko' 또는 'en')\n",
    "\n",
    "`generate_template_type`: 답변 생성 방식 ('reasoning': 풀이 과정 포함, 'only_answer': 답만 생성)\n",
    "\n",
    "`verbose_mode`: 상세 로그 출력 여부 (기본값: False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmetrics.metrics import MCQMetric\n",
    "metric = MCQMetric(\n",
    "    answer_model=deepseek_llm,\n",
    "    template_language='en',  # 'ko' 또는 'en'\n",
    "    generate_template_type='reasoning'  # 'reasoning' 또는 'only_answer'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case validate 검증 완료\n",
      "```json\n",
      "{\n",
      "    \"reasoning\": \"프랑스의 수도는 파리입니다. 런던은 영국의 수도, 베를린은 독일의 수도, 마드리드는 스페인의 수도입니다. 따라서 정답은 파리입니다. So the answer is B.\",\n",
      "    \"answer\": \"B\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "result = metric.measure(simple_testcase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input에 들어가 simple_testcase는 정답값과 함께 출력이 됨을 확인해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MCQTestCase(input='프랑스의 수도는 어디입니까?', choices=['런던', '파리', '베를린', '마드리드'], expected_output='B', output='B', reasoning='프랑스의 수도는 파리입니다. 런던은 영국의 수도, 베를린은 독일의 수도, 마드리드는 스페인의 수도입니다. 따라서 정답은 파리입니다. So the answer is B.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_testcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문제: 프랑스의 수도는 어디입니까?\n",
      "선택지: ['런던', '파리', '베를린', '마드리드']\n",
      "정답: B\n",
      "결과: 정답\n",
      "추론: 프랑스의 수도는 파리입니다. 런던은 영국의 수도, 베를린은 독일의 수도, 마드리드는 스페인의 수도입니다. 따라서 정답은 파리입니다. So the answer is B.\n",
      "토큰 사용량: {'completion_tokens': 70, 'prompt_tokens': 151, 'total_tokens': 221}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCQResult는 to_dict()와 from_dict() method를 지원합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = result.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MCQResult(question='프랑스의 수도는 어디입니까?', predicted='B', language='en', score=1, ground_truth='B', choice=['런던', '파리', '베를린', '마드리드'], reasoning=\"The question asks for the capital of France. Let's analyze the options step by step: A. 런던 (London) is the capital of the United Kingdom, not France. B. 파리 (Paris) is the correct capital of France. C. 베를린 (Berlin) is the capital of Germany, not France. D. 마드리드 (Madrid) is the capital of Spain, not France. So the answer is B.\", token_usage={'completion_tokens': 112, 'prompt_tokens': 150, 'total_tokens': 262})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.from_dict(result_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MCQ 템플릿 설정\n",
    "\n",
    "\n",
    "langmetrics의 Metric은 custom template을 이용할 수 있고, 이 template은 langchain의 Template을 이용하여 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, AIMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langmetrics.metrics import MCQTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메시지를 설정하되, 반드시 JSON을 output을 출력으로 뱉는 template을 설정해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt = ChatPromptTemplate.from_messages([\n",
    "    AIMessagePromptTemplate.from_template('당신은 의료 전문가입니다.'),\n",
    "    HumanMessagePromptTemplate.from_template(\"\"\"다음의 객관식 문제를 풀어주세요.\n",
    "추론 과정을 설명하고 정답은 알파벳(A, B, C, D 등)으로만 답해주세요.\n",
    "\n",
    "**\n",
    "중요 : 반드시 JSON 형식으로만 답변해주세요. 'answer' 키에는 정답을 작성해주세요.\n",
    "JSON 예시:\n",
    "{{\n",
    "\"answer\": \"<정답>\"\n",
    "}}\n",
    "**\n",
    "\n",
    "문제:\n",
    "{question}\n",
    "\n",
    "보기:\n",
    "{choices}\n",
    "\n",
    "JSON:\"\"\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCQTemplate 클래스는 정의된 프롬프트를 사용하여 객관식 문제 템플릿을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_template = MCQTemplate(prompt_for_answer=evaluation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = MCQMetric(\n",
    "    deepseek_llm, \n",
    "    verbose_mode=True, \n",
    "    template_language='en',\n",
    "    template=answer_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문제: 프랑스의 수도는 어디입니까?\n",
      "선택지: ['런던', '파리', '베를린', '마드리드']\n",
      "정답: B\n",
      "결과: 정답\n",
      "추론: The question asks for the capital of France. Let's analyze the options step by step: A. 런던 (London) is the capital of the United Kingdom, not France. B. 파리 (Paris) is the correct capital of France. C. 베를린 (Berlin) is the capital of Germany, not France. D. 마드리드 (Madrid) is the capital of Spain, not France. So the answer is B.\n",
      "토큰 사용량: None\n"
     ]
    }
   ],
   "source": [
    "print(metric.measure(simple_testcase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
